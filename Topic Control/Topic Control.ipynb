{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "<font color=blue>Name : Neha Patil <br>\n",
    "ID : 801081006</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "*Dataset 1 : 2009_04_28.txt* <br> After reading the conversations, I feel that Mara and Meg are the top two most influential people. I reached this conclusion because I observed that they are most active in accessing the candidates. Also, Mara introduces topics which later turn into debates.<br>\n",
    "\n",
    "*Dataset 2 : 2009_05_05.txt* <br> After reading the conversations, I feel that Amy and Jordan are the top two most influential people. I reached this conclusion because I observed that Amy is the one who acts as leader, concludes to stop discussion about previous candidate and introduces new candidates' resumes which become the topic of discussion later. Also, Jordan mentions about main characteristics observed from candidates' resumes which later turn into debates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "**Note :**\n",
    "1. The StanfordCoreNLP requires running Java Server which can be done using the following command - <br>java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 150000 \n",
    "2. If the parsed_text function gives an error 'string indices must be integers', it is because of timeout time in that function is less and increasing will resolve the error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dataset 1 : 2009_04_28.txt* <br> **Turn Length (TL)** measure results show that **Michael and Amy** are the top two most influential people. The results are not the same as that in Question 1. I observed that eventhough Mara introduces topics which turn into debates, she speaks less and more topic oriented. Similarly, although Mara and Meg are according to me, most active in accessing the candidates, they speak to the point and less as compared to others and hence, the results are different. <br>\n",
    "**Local Topic Introduction (LTI)** measure results show that **Michael and George** are the top two most influential people. The results are not the same as that in Question 1. As Michael is seems to be a top influencer according to both measures, I think I miss calculated his share in Topic Control. Also, I mainly considered introduction and accessment of new candidates as topic introduction but the LTI measure also takes into account other noun phrases which contribute as topic introductions and hence, the results are different.\n",
    "\n",
    "*Dataset 2 : 2009_05_05.txt* <br> **Turn Length (TL)** measure results show that **Michael and Amy** are the top two most influential people. The results are not the same as that in Question 1 although Amy is second most influential which is close to my observation. Michael talks a lot as compared to others but maybe I did not observe topic introductions in this conversations while reading. I picked Amy as she introduces candidates' resumes everytime which might also mean that she talk more and this drives the results obtained.\n",
    "**Local Topic Introduction (LTI)** measure results show that **Meg and Amy** are the top two most influential people. The results are not the same as that in Question 1 although Amy is second most influential which is close to my observation. I might have skipped the topics introduced by Meg as I mostly concentrated on introduction of candidates as topics which is done by Amy and hence Amy is one common person whereas Meg is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import operator\n",
    "import pprint\n",
    "from nltk.corpus import names\n",
    "from nltk import word_tokenize\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from fuzzywuzzy.process import dedupe as fuzzy_dedupe\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for question 2 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The following function extracts noun phrase subtrees from parsed chunk\"\"\"\n",
    "def extract_np(psent):\n",
    "  for subtree in psent.subtrees():\n",
    "    if subtree.label() == 'NP':\n",
    "      yield ' '.join(word for word, tag in subtree.leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function parses tagged sentences and returns noun phrases\"\"\"\n",
    "def nounPhrase(taggedSent):\n",
    "    nounPhraseList = []\n",
    "    grammar = r\"\"\"\n",
    "      NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "      {<NN>+}                 # chunk consecutive nouns\n",
    "      {<DT>?<JJ>*<NN>}\n",
    "      \"\"\"\n",
    "    #grammar = \"NP: {<DT>?<JJ>*<NN>}\" \n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    parsed_sent = cp.parse(taggedSent)\n",
    "    for npstr in extract_np(parsed_sent):\n",
    "        nounPhraseList.append(npstr)\n",
    "    return nounPhraseList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function annotates text using coreference resolver\"\"\"\n",
    "def parsed_text(text):\n",
    "    nlp = StanfordCoreNLP('http://127.0.0.1:9000')\n",
    "    output = nlp.annotate(text,properties={'timeout': '150000','annotators':'tokenize, ssplit, pos, depparse, parse, dcoref','outputFormat':'json'})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gender  totalwords                                               text\n",
      "0     michael            1                                             Hello.\n",
      "1         amy            1                                             Hello!\n",
      "2      george            2                                       good evening\n",
      "3     michael            1                                                 Hi\n",
      "4     michael           19    Sarah's name has been going between blue and...\n",
      "5         amy           14    An email just came in from meg that she won'...\n",
      "6      george            7               we get to hire someone else tonight!\n",
      "7         amy            9    that leaves mara and Yuan possibly coming la...\n",
      "8     michael            6                        Oh, hope she finds the cat.\n",
      "9         amy            2                                            Hi nick\n",
      "10    michael            1                                             george\n",
      "11     george            1                                               haha\n",
      "12     george           10    7 to 14 year olds need plenty of computer co...\n",
      "13        amy            8    yeah, in another job that requires People Sk...\n",
      "14        amy            5                       thats true george- a benefit\n",
      "15     george           13    who knows...perhaps they need help with thei...\n",
      "16    michael           37    Actually a computer expert at the Y would be...\n",
      "17        amy            1                                               hehe\n",
      "18        amy            8         i think the job descrip is lacking tonight\n",
      "19        amy           14    itdoesnt ally say what you'd be doing-  coun...\n",
      "20    michael           26    Yeah, would be nice if it said they are mana...\n",
      "21        amy           18    shall we assume it means working directly wi...\n",
      "22     george            8    perhaps by multi-task they mean do multiple ...\n",
      "23     george            9    like a multi-purpose job; whatever needs to ...\n",
      "24     george            6                   yea, it is a strange description\n",
      "25    michael           27    Man the desk today, plan a kids program for ...\n",
      "26        amy           25    communication skills, be outgoing and a self...\n",
      "27     george            9    so we prefer experience filling an unspecifi...\n",
      "28    michael           25    A lot of the staffers at the Y seem to do bo...\n",
      "29        amy            6                       and work with kids of course\n",
      "..         ...         ...                                                ...\n",
      "624    george            6                    mara, you are confusing me now!\n",
      "625       meg            4                               I'll forgive you now\n",
      "626      mara           10    haha i cant wait for tomorrow! or is it thur...\n",
      "627       meg            2                                           *for now\n",
      "628       amy            8                  i think we are done for the night\n",
      "629       meg            2                                             Me too\n",
      "630       amy            7                    i think we're set for the night\n",
      "631  michelle            4                          who will interview Carla?\n",
      "632       meg            3                                    Good night guys\n",
      "633       meg            3                                     I'm going home\n",
      "634       meg            0                                                   \n",
      "635       amy            2                                    Night everyone!\n",
      "636       meg            1                                          moderator\n",
      "637       meg            1                                             Hahaha\n",
      "638      mara           14    i picked carla, meg picked richard... so i a...\n",
      "639      mara            3                                     got it george?\n",
      "640       meg            1                                           Hahahaha\n",
      "641       meg            1                                             Thanks\n",
      "642       meg            1                                                lol\n",
      "643      mara            1                                         GOODNIGHT!\n",
      "644       meg           16    Ok I'm really getting out of here now I have...\n",
      "645       amy            3                                     i'm back Thurs\n",
      "646       meg            1                                               Bye!\n",
      "647    george            3                                        must be lag\n",
      "648       amy            1                                                LOL\n",
      "649    george            5                      ok guys was fun...good night!\n",
      "650   michael            2                                       Sounds good.\n",
      "651  michelle            2                                         good night\n",
      "652   michael            1                                           michelle\n",
      "653   michael            2                                        Good night.\n",
      "\n",
      "[654 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data1File1 = pd.read_csv('2009_04_28.txt', sep='(' , names =[\"gender\",\"text\"])\n",
    "finalFile1 = data1File1.drop(['text'], axis = 1)\n",
    "data2File1 = pd.read_csv('2009_04_28.txt', sep=':' , names =[\"names\",\"time1\",\"time2\",\"text\"])\n",
    "finalFile1['totalwords'] = data2File1['text'].str.split().str.len()\n",
    "finalFile1['text'] = data2File1['text']\n",
    "print(finalFile1)\n",
    "LTIdata1 = finalFile1.drop(['totalwords'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn Length -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of michael is 1 with TL count 11.405405405405405\n",
      "Rank of amy is 2 with TL count 7.318518518518519\n",
      "Rank of mara is 3 with TL count 7.1875\n",
      "Rank of george is 4 with TL count 7.070588235294117\n",
      "Rank of nick is 5 with TL count 7.0285714285714285\n",
      "Rank of michelle is 6 with TL count 4.24\n",
      "Rank of meg is 7 with TL count 3.8284313725490198\n"
     ]
    }
   ],
   "source": [
    "nameList1 = list(set(data1File1['gender']))\n",
    "wordCount1 = {}\n",
    "nameCount1 = {}\n",
    "TLCount1 = {}\n",
    "LTICount1 = {}\n",
    "CCS1 = {}\n",
    "for name in nameList1:\n",
    "    wordCount1[name] = 0\n",
    "    nameCount1[name] = 0\n",
    "    LTICount1[name] = 0\n",
    "    CCS1[name] = 0\n",
    "for index,rows  in finalFile1.iterrows():\n",
    "    wordCount1[rows['gender']] = wordCount1[rows['gender']] + rows['totalwords']\n",
    "    nameCount1[rows['gender']] = nameCount1[rows['gender']] + 1\n",
    "#print (nameCount1)\n",
    "#print (wordCount1)\n",
    "for name in nameList1:\n",
    "    TLCount1[name] = wordCount1[name]/nameCount1[name]\n",
    "sorted_TLCount1 = sorted(TLCount1.items(), key=operator.itemgetter(1))\n",
    "for i in range(len(sorted_TLCount1)-1,-1, -1):\n",
    "    print('Rank of ' + sorted_TLCount1[i][0] + 'is ' + str(len(sorted_TLCount1)-i) + ' with TL count ' + str(sorted_TLCount1[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Topic Introduction -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here we get all the noun phrases in NPListTogether1\"\"\"\n",
    "NPListTogether1 = []\n",
    "path = (\"2009_04_28.txt\")\n",
    "with open(path) as sample_text:\n",
    "    for lines in sample_text:\n",
    "        lowers = lines.lower()\n",
    "        text1 = word_tokenize(lowers)\n",
    "        tags1 = nltk.pos_tag(text1) \n",
    "        currentList = nounPhrase(tags1)\n",
    "        NPListTogether1.append(currentList)\n",
    "#print(NPListTogether1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We are extracting only the textual data from the files\"\"\"\n",
    "completeText1 = ''\n",
    "for index,rows  in LTIdata1.iterrows():\n",
    "    if rows['text'][-1:] != '.' and rows['text'][-1:] != '?' and rows['text'][-1:] != '!':\n",
    "        completeText1 = completeText1 + (rows['text']) + '.'\n",
    "    else:\n",
    "        completeText1 = completeText1 + (rows['text'])\n",
    "#print(completeText)\n",
    "s1 = parsed_text(completeText1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We are getting unique coreferences here\"\"\"\n",
    "uniqueCoref1 = []\n",
    "for key in s1['corefs']:\n",
    "    for value in s1['corefs'][key]:\n",
    "        if value['isRepresentativeMention'] == True:\n",
    "            uniqueCoref1.append(value['text'])\n",
    "#print(uniqueCoref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of michael is 1 with LTI count 206\n",
      "Rank of george is 2 with LTI count 136\n",
      "Rank of amy is 3 with LTI count 129\n",
      "Rank of meg is 4 with LTI count 34\n",
      "Rank of nick is 5 with LTI count 25\n",
      "Rank of mara is 6 with LTI count 21\n",
      "Rank of michelle is 7 with LTI count 1\n"
     ]
    }
   ],
   "source": [
    "for item in uniqueCoref1:\n",
    "    flag = 0;\n",
    "    if flag == 0:\n",
    "        for i in range(0,len(NPListTogether1)):\n",
    "            if flag == 0:\n",
    "                for element in NPListTogether1[i]:\n",
    "                    if item == element or element in item:\n",
    "                        if len(element) > 1:\n",
    "                            LTICount1[LTIdata1['gender'][i]] = LTICount1[LTIdata1['gender'][i]] + 1\n",
    "                            flag = 1;\n",
    "                            break\n",
    "\n",
    "sorted_LTICount1 = sorted(LTICount1.items(), key=operator.itemgetter(1))\n",
    "for i in range(len(sorted_LTICount1)-1,-1, -1):\n",
    "    print('Rank of ' + sorted_LTICount1[i][0] + 'is ' + str(len(sorted_LTICount1)-i) + ' with LTI count ' + str(sorted_LTICount1[i][1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gender  totalwords                                               text\n",
      "0         meg            2                                          Hi george\n",
      "1     michael            1                                             Hello.\n",
      "2         meg            3                                       How are you?\n",
      "3         meg            1                                                 Hi\n",
      "4      george            1                                                 hi\n",
      "5        nick            1                                                 hi\n",
      "6      george            7                  i gonna heat up instant ramen brb\n",
      "7        nick            1                                              jinx!\n",
      "8     michael           11     Can you get out of it by seeing a punch buggy?\n",
      "9         meg            3                                        I think so!\n",
      "10        meg            1                                             Hahaha\n",
      "11    michael           10       {o^o) - there we go. It has wheels at least.\n",
      "12     jordan            2                                      Hi, everyone.\n",
      "13        meg            1                                                 Hi\n",
      "14    michael            1                                              Hello\n",
      "15        amy            2                                         Hello room\n",
      "16     jordan            7                 You guys were not here last night?\n",
      "17    michael            3                                      <br />room (8\n",
      "18    michael            3                                        hmm, no fun\n",
      "19       nick            2                                              i was\n",
      "20        meg           12    I was supposed to be but I think I got food ...\n",
      "21    michael            5                            Ah, I wasn't, at least.\n",
      "22       john            2                                       Hi, everyone\n",
      "23    michael            1                                                 Hi\n",
      "24        amy            1                                              hello\n",
      "25     jordan            5                 food poisoning? that serious, meg?\n",
      "26        meg            6                               Yeah, or a 24 hr bug\n",
      "27        meg            3                                   Bad stomach ache\n",
      "28        meg            0                                                   \n",
      "29     jordan            5                                r ur all right now?\n",
      "..         ...         ...                                                ...\n",
      "893       meg            3                                   it's REALLY good\n",
      "894    george           17    ok guys good night, i think this will get to...\n",
      "895   michael            5                         How did they reproduce? Oo\n",
      "896       amy            3                                    not sure jordan\n",
      "897       amy            4                               what that one about?\n",
      "898    jordan            3                                   seen that novie?\n",
      "899    jordan            1                                              movie\n",
      "900       meg            2                                         Bye george\n",
      "901   michael           12    I think there have been matriarchal societie...\n",
      "902      nick            3                              The Yellow Wallpaper?\n",
      "903   michael            9    Although men were still there, just not in c...\n",
      "904       meg            5                                 I gotta go now too\n",
      "905       meg            5                              Have a good night all\n",
      "906    jordan            9    Gilman sees to me a stream of conscious writer.\n",
      "907       amy           20    i actually dont remember how they reproduced...\n",
      "908   michael            1                                             george\n",
      "909  michelle            2                                       which movie?\n",
      "910    jordan           12    a woman lying in bed watching hr ceiling, an...\n",
      "911  michelle            1                                                 no\n",
      "912      nick            4                                  OK good night all\n",
      "913    jordan            1                                                 88\n",
      "914       amy            1                                             NIght!\n",
      "915      john            3                                     good night all\n",
      "916       amy           11    i'll write down the Tellow Spot and trey and...\n",
      "917    jordan            3                                   goonnight ye all\n",
      "918   michael            1                                             'night\n",
      "919  michelle            4                     jordan, nice conversation, bye\n",
      "920       amy           16    it is that time!  See you guys tomorrow if y...\n",
      "921  michelle            1                                    byebye,everyone\n",
      "922    jordan            8    good night , good night goodnight! says Ophelia\n",
      "\n",
      "[923 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data1File2 = pd.read_csv('2009_05_05.txt', sep='(' , names =[\"gender\",\"text\"])\n",
    "finalFile2 = data1File2.drop(['text'], axis = 1)\n",
    "data2File2 = pd.read_csv('2009_05_05.txt', sep=':' , names =[\"names\",\"time1\",\"time2\",\"text\"])\n",
    "finalFile2['totalwords'] = data2File2['text'].str.split().str.len()\n",
    "finalFile2['text'] = data2File2['text']\n",
    "print(finalFile2)\n",
    "LTIdata2 = finalFile2.drop(['totalwords'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn Length -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of michael is 1 with TL count 9.0\n",
      "Rank of amy is 2 with TL count 6.7251461988304095\n",
      "Rank of george is 3 with TL count 6.285714285714286\n",
      "Rank of nick is 4 with TL count 5.852941176470588\n",
      "Rank of mara is 5 with TL count 5.2\n",
      "Rank of jordan is 6 with TL count 4.7846153846153845\n",
      "Rank of michelle is 7 with TL count 4.22680412371134\n",
      "Rank of meg is 8 with TL count 3.757085020242915\n",
      "Rank of john is 9 with TL count 2.506666666666667\n"
     ]
    }
   ],
   "source": [
    "nameList2 = list(set(data1File2['gender']))\n",
    "wordCount2 = {}\n",
    "nameCount2 = {}\n",
    "TLCount2 = {}\n",
    "LTICount2 = {}\n",
    "CCS2 = {}\n",
    "for name in nameList2:\n",
    "    wordCount2[name] = 0\n",
    "    nameCount2[name] = 0\n",
    "    LTICount2[name] = 0\n",
    "    CCS2[name] = 0\n",
    "for index,rows  in finalFile2.iterrows():\n",
    "    wordCount2[rows['gender']] = wordCount2[rows['gender']] + rows['totalwords']\n",
    "    nameCount2[rows['gender']] = nameCount2[rows['gender']] + 1\n",
    "#print (nameCount2)\n",
    "#print (wordCount2)\n",
    "for name in nameList2:\n",
    "    TLCount2[name] = wordCount2[name]/nameCount2[name]\n",
    "sorted_TLCount2 = sorted(TLCount2.items(), key=operator.itemgetter(1))\n",
    "for i in range(len(sorted_TLCount2)-1,-1, -1):\n",
    "    print('Rank of ' + sorted_TLCount2[i][0] + 'is ' + str(len(sorted_TLCount2)-i) + ' with TL count ' + str(sorted_TLCount2[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Topic Introduction -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here we get all the noun phrases in NPListTogether2\"\"\"\n",
    "NPListTogether2 = []\n",
    "path = (\"2009_05_05.txt\")\n",
    "with open(path) as sample_text:\n",
    "    for lines in sample_text:\n",
    "        lowers = lines.lower()\n",
    "        text1 = word_tokenize(lowers)\n",
    "        tags1 = nltk.pos_tag(text1) \n",
    "        currentList = nounPhrase(tags1)\n",
    "        NPListTogether2.append(currentList)\n",
    "#print(NPListTogether2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We are extracting only the textual data from the files\"\"\"\n",
    "completeText2 = ''\n",
    "for index,rows  in LTIdata2.iterrows():\n",
    "    if rows['text'][-1:] != '.' and rows['text'][-1:] != '?' and rows['text'][-1:] != '!':\n",
    "        completeText2 = completeText2 + (rows['text']) + '.'\n",
    "    else:\n",
    "        completeText2 = completeText2 + (rows['text'])\n",
    "#print(completeText)\n",
    "s2 = parsed_text(completeText2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We are getting unique coreferences here\"\"\"\n",
    "uniqueCoref2 = []\n",
    "for key in s2['corefs']:\n",
    "    for value in s2['corefs'][key]:\n",
    "        if value['isRepresentativeMention'] == True:\n",
    "            uniqueCoref2.append(value['text'])\n",
    "#print(uniqueCoref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of meg is 1 with LTI count 151\n",
      "Rank of amy is 2 with LTI count 136\n",
      "Rank of michael is 3 with LTI count 117\n",
      "Rank of george is 4 with LTI count 46\n",
      "Rank of nick is 5 with LTI count 43\n",
      "Rank of michelle is 6 with LTI count 32\n",
      "Rank of jordan is 7 with LTI count 31\n",
      "Rank of john is 8 with LTI count 8\n",
      "Rank of mara is 9 with LTI count 3\n"
     ]
    }
   ],
   "source": [
    "for item in uniqueCoref2:\n",
    "    flag = 0;\n",
    "    if flag == 0:\n",
    "        for i in range(0,len(NPListTogether2)):\n",
    "            if flag == 0:\n",
    "                for element in NPListTogether2[i]:\n",
    "                    if item == element or element in item:\n",
    "                        if len(element) > 1:\n",
    "                            LTICount2[LTIdata2['gender'][i]] = LTICount2[LTIdata2['gender'][i]] + 1\n",
    "                            flag = 1;\n",
    "                            break\n",
    "\n",
    "sorted_LTICount2 = sorted(LTICount2.items(), key=operator.itemgetter(1))\n",
    "for i in range(len(sorted_LTICount2)-1,-1, -1):\n",
    "    print('Rank of ' + sorted_LTICount2[i][0] + 'is ' + str(len(sorted_LTICount2)-i) + ' with LTI count ' + str(sorted_LTICount2[i][1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "Candidate Citation Score (CCS) measure counts the number of times each participant talks about the candidates under review. I believe this measure will be helpful because the outcome of both the discussions are choosing a candidate the participants find to be worthy for the specified job and this measure takes into account how each participant contributes in the final outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dataset 1 : 2009_04_28.txt* <br> **Candidate Citation Score (CCS)** measure results show that **George and Amy** are the top two most influential people. The results are not the same as that in Question 1. I considered Mara and Meg to be the top ones because I thought they are the most active ones in accessing the candidates. Maybe rereading the conversations might change my results. There can be two possibilities either I miss calculated in determining the top influencers or CCS measure should be combined with other measure to better find the top influencers.\n",
    "\n",
    "*Dataset 2 : 2009_05_05.txt* <br> **Candidate Citation Score (CCS)** measure results show that **Michelle and George** are the top two most influential people. The results are not the same as that in Question 1. I considered Amy and Jordan to be the top ones because I considered only introduction of candidates and their characteristics as main topics. Maybe rereading the conversations might change my results. This idea of this measure is completely different than the one I used in Question 1 and hence the results are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for question 3 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function returns the set of people found within the sentence\"\"\"\n",
    "def proc_sentence(tokens):\n",
    "    people = set()\n",
    "    token_count = 0\n",
    "    for i in range(len(tokens)):\n",
    "        if token_count < len(tokens):\n",
    "            person = ''\n",
    "            token = tokens[token_count]\n",
    "            if token['ner'] == 'PERSON':\n",
    "                person += token['word'].lower()\n",
    "                checking = True\n",
    "                while checking == True:\n",
    "                    if token_count + 1 < len(tokens):\n",
    "                        if tokens[token_count + 1]['ner'] == 'PERSON':\n",
    "                            token_count += 1\n",
    "                            person += ' {}'.format(tokens[token_count]['word'].lower())\n",
    "                        else:\n",
    "                            checking = False\n",
    "                            token_count += 1\n",
    "                    else:\n",
    "                        checking = False\n",
    "                        token_count += 1\n",
    "            else:\n",
    "                token_count += 1\n",
    "            if person != '':\n",
    "                people.add(person)\n",
    "    return people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Using fuzzywuzzy to take care of partial representations of entities\"\"\"\n",
    "def proc_article(article):\n",
    "    output = nlp.annotate(article, properties={\n",
    "      'annotators': 'ner',\n",
    "      'outputFormat': 'json'\n",
    "      })\n",
    "    \n",
    "    people_super = set()\n",
    "    for sent in output['sentences']:\n",
    "        people = proc_sentence(sent['tokens'])\n",
    "        for person in people:\n",
    "            people_super.add(person)\n",
    "\n",
    "    contains_dupes = list(people_super)\n",
    "    \n",
    "    deduped = fuzzy_dedupe(contains_dupes)\n",
    "    \n",
    "    return deduped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Citation Score - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of george is 1 with Candidate Citation count 30\n",
      "Rank of amy is 2 with Candidate Citation count 19\n",
      "Rank of mara is 3 with Candidate Citation count 11\n",
      "Rank of meg is 4 with Candidate Citation count 7\n",
      "Rank of nick is 5 with Candidate Citation count 1\n",
      "Rank of michelle is 6 with Candidate Citation count 1\n",
      "Rank of michael is 7 with Candidate Citation count 0\n"
     ]
    }
   ],
   "source": [
    "allNames1 =  list(proc_article(completeText1))\n",
    "for index,rows  in finalFile1.iterrows():\n",
    "    currentText = rows['text']\n",
    "    for element in allNames1:\n",
    "        if element in currentText:\n",
    "            CCS1[rows['gender']] = CCS1[rows['gender']] + 1;\n",
    "sorted_CCS1 = sorted(CCS1.items(), key=operator.itemgetter(1))\n",
    "for i in range(len(sorted_CCS1)-1,-1, -1):\n",
    "    print('Rank of ' + sorted_CCS1[i][0] + 'is ' + str(len(sorted_CCS1)-i) + ' with Candidate Citation score ' + str(sorted_CCS1[i][1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of michelle is 1 with Candidate Citation count 11\n",
      "Rank of george is 2 with Candidate Citation count 10\n",
      "Rank of amy is 3 with Candidate Citation count 9\n",
      "Rank of john is 4 with Candidate Citation count 2\n",
      "Rank of michael is 5 with Candidate Citation count 2\n",
      "Rank of meg is 6 with Candidate Citation count 1\n",
      "Rank of jordan is 7 with Candidate Citation count 1\n",
      "Rank of nick is 8 with Candidate Citation count 0\n",
      "Rank of mara is 9 with Candidate Citation count 0\n"
     ]
    }
   ],
   "source": [
    "allNames2 =  list(proc_article(completeText2))\n",
    "for index,rows  in finalFile2.iterrows():\n",
    "    currentText = rows['text']\n",
    "    for element in allNames2:\n",
    "        if element in currentText:\n",
    "            CCS2[rows['gender']] = CCS2[rows['gender']] + 1;\n",
    "sorted_CCS2 = sorted(CCS2.items(), key=operator.itemgetter(1))\n",
    "for i in range(len(sorted_CCS2)-1,-1, -1):\n",
    "    print('Rank of ' + sorted_CCS2[i][0] + 'is ' + str(len(sorted_CCS2)-i) + ' with Candidate Citation score ' + str(sorted_CCS2[i][1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "Modeling influence is an interesting topic. I learned new concepts like co-reference resolver and network centrality. Along the way, I learned about different libraries and their uses like, fuzzywuzzy and networkx. Most important outcome from this assignment was learning about the StanfordCoreNLP framework, the tools it provides and understanding how to apply the tools to get desired results. <br>\n",
    "Also, coming up with relevant measures for modeling influence is an important task. I also encountered that Local Topic Introduction measure can also be derived using LDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References :\n",
    "1. http://brandonrose.org/ner2sna\n",
    "2. https://stackoverflow.com/questions/33815401/nltk-how-do-i-traverse-a-noun-phrase-to-return-list-of-strings\n",
    "3. https://www.analyticsvidhya.com/blog/2019/02/stanfordnlp-nlp-library-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
